{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noexport\n",
    "\n",
    "import os\n",
    "os.system('export_notebook reconstruct_spans_persecond.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 0))\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6d3b788ecde2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/sklearn/svm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# License: BSD 3 clause (C) INRIA 2010\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNuSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNuSVR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOneClassSVM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mLinearSVR\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0ml1_min_c\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_fit_liblinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseLibSVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRegressorMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseCoefMixin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibsvm_sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mChangedBehaviorWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/sklearn/preprocessing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mimputation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/sklearn/preprocessing/imputation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_lazywhere\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[0;32m     11\u001b[0m                                     rv_frozen)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/ve/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mnew\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minstancemethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gkovacs/.locinst/lib/python2.7/new.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mno\u001b[0m \u001b[0mlonger\u001b[0m \u001b[0mrequired\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mObjects\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mnow\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \"\"\"\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnpy3k\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m warnpy3k(\"The 'new' module has been removed in Python 3.0; use the 'types' \"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tmilib import *\n",
    "\n",
    "from reconstruct_focus_times_common import *\n",
    "from sorted_collection import SortedCollection\n",
    "from rescuetime_utils import *\n",
    "\n",
    "import sklearn\n",
    "import sklearn.svm\n",
    "import sklearn.linear_model\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "\n",
    "from math import log\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_users = get_training_users()\n",
    "test_users = get_test_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print domain_to_id('www.facebook.com')\n",
    "#print id_to_domain(29708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_secondlevel_dataset_from_users(users):\n",
    "  all_labels = []\n",
    "  all_sinceprev = []\n",
    "  all_tonext = []\n",
    "  all_fromdomain = []\n",
    "  all_todomain = []\n",
    "  for user in users:\n",
    "    data = extract_secondlevel_dataset_from_user(user)\n",
    "    all_labels.extend(data['label'])\n",
    "    all_sinceprev.extend(data['sinceprev'])\n",
    "    all_tonext.extend(data['tonext'])\n",
    "    all_fromdomain.extend(data['fromdomain'])\n",
    "    all_todomain.extend(data['todomain'])\n",
    "  return {\n",
    "    'label': all_labels,\n",
    "    'sinceprev': all_sinceprev,\n",
    "    'tonext': all_tonext,\n",
    "    'fromdomain': all_fromdomain,\n",
    "    'todomain': all_todomain,\n",
    "  }\n",
    "\n",
    "@jsonmemoized\n",
    "def extract_secondlevel_dataset_for_training():\n",
    "  return extract_secondlevel_dataset_from_users(training_users)\n",
    "\n",
    "@jsonmemoized\n",
    "def extract_secondlevel_dataset_for_test():\n",
    "  return extract_secondlevel_dataset_from_users(test_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_tensecondlevel_dataset_from_users(users):\n",
    "  all_labels = []\n",
    "  all_sinceprev = []\n",
    "  all_tonext = []\n",
    "  all_fromdomain = []\n",
    "  all_todomain = []\n",
    "  for user in users:\n",
    "    data = extract_secondlevel_dataset_from_user(user, True)\n",
    "    all_labels.extend(data['label'])\n",
    "    all_sinceprev.extend(data['sinceprev'])\n",
    "    all_tonext.extend(data['tonext'])\n",
    "    all_fromdomain.extend(data['fromdomain'])\n",
    "    all_todomain.extend(data['todomain'])\n",
    "  return {\n",
    "    'label': all_labels,\n",
    "    'sinceprev': all_sinceprev,\n",
    "    'tonext': all_tonext,\n",
    "    'fromdomain': all_fromdomain,\n",
    "    'todomain': all_todomain,\n",
    "  }\n",
    "\n",
    "@jsonmemoized\n",
    "def extract_tensecondlevel_dataset_for_training():\n",
    "  return extract_tensecondlevel_dataset_from_users(training_users)\n",
    "\n",
    "@jsonmemoized\n",
    "def extract_tensecondlevel_dataset_for_test():\n",
    "  return extract_tensecondlevel_dataset_from_users(test_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a=extract_secondlevel_training_data_from_user(training_users[0])\n",
    "#print 'extracting dataset for training'\n",
    "#extract_secondlevel_dataset_for_training()\n",
    "#extract_tensecondlevel_dataset_for_training()\n",
    "#print 'extracting dataset for test'\n",
    "#extract_secondlevel_dataset_for_test()\n",
    "#extract_tensecondlevel_dataset_for_test()\n",
    "#print 'extraction done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print zipkeys({'a':[3,4,5], 'b':[6,7,8]}, 'a', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@memoized\n",
    "def total_usage_of_domains_in_training():\n",
    "  return sum_values_in_list_of_dict([get_domain_to_time_spent_for_user(user)for user in training_users])\n",
    "\n",
    "@memoized\n",
    "def top_n_domains_by_usage(n=10):\n",
    "  domain_to_usage = total_usage_of_domains_in_training()\n",
    "  return [x[0] for x in sorted(domain_to_usage.items(), key=itemgetter(1), reverse=True)[:n]]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print top_n_domains_by_visits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print top_n_domains_by_usage(10)\n",
    "#print top_n_domains_by_usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print domain_to_id('newtab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def dataset_to_feature_vectors(dataset):\n",
    "  topdomains = numpy.array([domain_to_id(x) for x in top_n_domains_by_visits(20)])\n",
    "  num_features = 3 + 2*len(topdomains) + 2*len(get_rescuetime_productivity_levels())\n",
    "  output = [[0]*num_features for x in xrange(len(dataset['sinceprev']))]\n",
    "  #output = numpy.zeros((len(dataset['sinceprev']), num_features), dtype=object) # object instead of float, so we can have floats and ints\n",
    "  for idx,sinceprev,tonext,fromdomain,todomain in zipkeys_idx(dataset, 'sinceprev', 'tonext', 'fromdomain', 'todomain'):\n",
    "    cur = output[idx]\n",
    "    cur[0] = sinceprev\n",
    "    cur[1] = tonext\n",
    "    cur[2] = int(fromdomain == todomain)\n",
    "    feature_num = 3\n",
    "    for domain_idx,domain in enumerate(topdomains):\n",
    "      cur[feature_num+domain_idx] = int(fromdomain == domain)\n",
    "    feature_num += len(topdomains)\n",
    "    for domain_idx,domain in enumerate(topdomains):\n",
    "      cur[feature_num+domain_idx] = int(todomain == domain)\n",
    "    feature_num += len(topdomains)\n",
    "    fromdomain_name = id_to_domain(fromdomain)\n",
    "    todomain_name = id_to_domain(todomain)\n",
    "    fromdomain_productivity = domain_to_productivity(fromdomain_name)\n",
    "    todomain_productivity = domain_to_productivity(todomain_name)\n",
    "    for productivity_idx,productivity in enumerate(get_rescuetime_productivity_levels()):\n",
    "      cur[feature_num+productivity_idx] = int(fromdomain_productivity == productivity)\n",
    "    feature_num += len(get_rescuetime_productivity_levels())\n",
    "    for productivity_idx,productivity in enumerate(get_rescuetime_productivity_levels()):\n",
    "      cur[feature_num+productivity_idx] = int(todomain_productivity == productivity)\n",
    "    feature_num += len(get_rescuetime_productivity_levels())\n",
    "  return output\n",
    "'''\n",
    "\n",
    "def remove_cached_features():\n",
    "  os.remove('get_test_feature_vector.msgpack')\n",
    "  os.remove('get_training_feature_vector.msgpack')\n",
    "  #os.remove('get_test_labels.msgpack')\n",
    "  #os.remove('get_training_labels.msgpack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove_cached_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@msgpackmemoized\n",
    "def get_training_feature_vector():\n",
    "  return dataset_to_feature_vectors(extract_tensecondlevel_dataset_for_training())\n",
    "\n",
    "@msgpackmemoized\n",
    "def get_training_labels():\n",
    "  return extract_tensecondlevel_dataset_for_training()['label']\n",
    "\n",
    "@msgpackmemoized\n",
    "def get_test_feature_vector():\n",
    "  return dataset_to_feature_vectors(extract_tensecondlevel_dataset_for_test())\n",
    "\n",
    "@msgpackmemoized\n",
    "def get_test_labels():\n",
    "  return extract_tensecondlevel_dataset_for_test()['label']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def train_classifier_on_data(training_data):\n",
    "  #classifier = sklearn.tree.DecisionTreeClassifier(max_depth=2) # .71 on test\n",
    "  #classifier = sklearn.tree.DecisionTreeClassifier(max_depth=1)\n",
    "  #classifier = sklearn.tree.DecisionTreeClassifier()\n",
    "  #classifier = sklearn.naive_bayes.GaussianNB() # .73 on test\n",
    "  #classifier = sklearn.svm.LinearSVC()\n",
    "  #classifier = sklearn.linear_model.SGDClassifier(class_weight='balanced')\n",
    "  classifier = sklearn.linear_model.SGDClassifier(loss='modified_huber') # .73 on test\n",
    "  classifier.fit(dataset_to_feature_vectors(training_data), numpy.array(training_data['label']))\n",
    "  return classifier\n",
    "\n",
    "def get_classifier():\n",
    "  return train_classifier_on_data(extract_tensecondlevel_dataset_for_training())\n",
    "'''\n",
    "\n",
    "def get_feature_filter():\n",
    "  #return '11000000000000000000000000000000000000000000000000000'\n",
    "  #return '11111111111111111111111111111111111111111111111111111'\n",
    "  return '11100000000000000000000000000000000000000000000000000'\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
    "  #selected_features = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "  #selected_features = [True,False,True,False,False,False,False,True,True,False,True,False]\n",
    "  return ''.join(map(str, selected_features))\n",
    "\n",
    "'''\n",
    "def get_filtered_features():\n",
    "  selected_features = get_feature_filter()\n",
    "  selected_features_str = ''.join(map(str, selected_features))\n",
    "  selected_features_filename = 'filtered_features_' + selected_features_str + '.msgpack'\n",
    "  if path.exists(selected_features_filename):\n",
    "    #return numpy.loadtxt()\n",
    "    #return json.load(open(selected_features_filename))\n",
    "    return msgpack.load(open(selected_features_filename))\n",
    "  output = filter_features(get_training_feature_vector())\n",
    "  msgpack.dump(output, open(selected_features_filename, 'w'))\n",
    "  #json.dump(output, open(selected_features_filename, 'w'))\n",
    "  return output\n",
    "'''\n",
    "\n",
    "'''\n",
    "def get_filtered_features_train():\n",
    "  selected_features = get_feature_filter()\n",
    "  selected_features_str = ''.join(map(str, selected_features))\n",
    "  selected_features_filename = 'features_train_' + selected_features_str + '.msgpack'\n",
    "  if path.exists(selected_features_filename):\n",
    "    return msgpack.load(open(selected_features_filename))\n",
    "  output = dataset_to_feature_vectors(extract_tensecondlevel_dataset_for_training(), selected_features)\n",
    "  msgpack.dump(output, open(selected_features_filename, 'w'))\n",
    "  return output\n",
    "\n",
    "def get_filtered_features_test():\n",
    "  selected_features = get_feature_filter()\n",
    "  selected_features_str = ''.join(map(str, selected_features))\n",
    "  selected_features_filename = 'features_test_' + selected_features_str + '.msgpack'\n",
    "  if path.exists(selected_features_filename):\n",
    "    return msgpack.load(open(selected_features_filename))\n",
    "  output = dataset_to_feature_vectors(extract_tensecondlevel_dataset_for_test(), selected_features)\n",
    "  msgpack.dump(output, open(selected_features_filename, 'w'))\n",
    "  return output\n",
    "'''\n",
    "\n",
    "'''\n",
    "def get_filtered_features_train():\n",
    "  selected_features = get_feature_filter()\n",
    "  return get_feature_vector_for_tensecondlevel_train(selected_features)\n",
    "\n",
    "def get_filtered_features_test():\n",
    "  selected_features = get_feature_filter()\n",
    "  return get_feature_vector_for_tensecondlevel_test(selected_features)\n",
    "\n",
    "def get_test_labels():\n",
    "  return get_labels_for_tensecondlevel_test()\n",
    "\n",
    "def get_training_labels():\n",
    "  return get_labels_for_tensecondlevel_train()\n",
    "\n",
    "def get_labels_for_user(user):\n",
    "  return get_tensecondlevel_activespan_labels_for_user(user)\n",
    "'''\n",
    "\n",
    "# we normally want to use the tensecond level ones\n",
    "def get_filtered_features_train():\n",
    "  selected_features = get_feature_filter()\n",
    "  return get_feature_vector_for_secondlevel_train(selected_features)\n",
    "\n",
    "def get_filtered_features_test():\n",
    "  selected_features = get_feature_filter()\n",
    "  return get_feature_vector_for_secondlevel_test(selected_features)\n",
    "\n",
    "def get_test_labels():\n",
    "  return get_labels_for_secondlevel_test()\n",
    "\n",
    "def get_training_labels():\n",
    "  return get_labels_for_secondlevel_train()\n",
    "\n",
    "def get_labels_for_user(user):\n",
    "  return get_secondlevel_activespan_labels_for_user(user)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def filter_features(arr):\n",
    "  # from get_selected_features()\n",
    "  selected_features = get_feature_filter()\n",
    "  #selected_feature_idx = [i for i,x in enumerate(selected_features) if x]\n",
    "  #return arr[:,selected_feature_idx]\n",
    "  output = []\n",
    "  for line in arr:\n",
    "    output.append([line[i] for i,x in enumerate(selected_features) if x])\n",
    "    #output.append([x for i,x in enumerate(line) if selected_features[i]])\n",
    "  return output\n",
    "'''\n",
    "\n",
    "def get_classifier():\n",
    "  #classifier = sklearn.naive_bayes.GaussianNB()\n",
    "  #classifier = sklearn.linear_model.SGDClassifier(loss='modified_huber') # .73 on test\n",
    "  #classifier = sklearn.linear_model.SGDClassifier()\n",
    "  classifier = sklearn.ensemble.RandomForestClassifier()\n",
    "  classifier.fit(get_filtered_features_train(), get_training_labels())\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a=get_filtered_features_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b=get_test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print len(get_feature_filter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print len(get_training_feature_vector()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def make_predictions_with_classifier_on_dataset(classifier, dataset):\n",
    "  return classifier.predict(dataset_to_feature_vectors(dataset))\n",
    "\n",
    "def make_proba_predictions_with_classifier_on_dataset(classifier, dataset):\n",
    "  return [x[1] for x in classifier.predict_proba(dataset_to_feature_vectors(dataset))]\n",
    "\n",
    "def evaluate_classifier(classifier):\n",
    "  test_predictions = make_predictions_with_classifier_on_dataset(classifier, test_data)\n",
    "  print sklearn.metrics.classification_report(test_data['label'], test_predictions)\n",
    "'''\n",
    "\n",
    "def make_predictions_with_classifier_on_test(classifier):\n",
    "  #return classifier.predict(filter_features(numpy.array(get_test_feature_vector())))\n",
    "  return classifier.predict(get_filtered_features_test())\n",
    "\n",
    "def evaluate_classifier(classifier):\n",
    "  test_predictions = make_predictions_with_classifier_on_test(classifier)\n",
    "  print sklearn.metrics.classification_report(get_test_labels(), test_predictions)\n",
    "\n",
    "def evaluate_classifier_for_user(classifier, user):\n",
    "  dataset = extract_secondlevel_dataset_from_user(user, True)\n",
    "  test_labels = get_labels_for_user(user)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a= get_training_feature_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_selected_features_rfe():\n",
    "  classifier = sklearn.linear_model.SGDClassifier()\n",
    "  selector = sklearn.feature_selection.RFE(classifier, 10, step=1)\n",
    "  selector = selector.fit(numpy.array(get_training_feature_vector()), numpy.array(get_training_labels()))\n",
    "  return {\n",
    "    'n_features': selector.n_features_,\n",
    "    'support': map(int, selector.support_),\n",
    "    'ranking': map(int, selector.ranking_),\n",
    "  }\n",
    "  # return selector.ranking_\n",
    "\n",
    "def get_selected_features_rfecv():\n",
    "  classifier = sklearn.linear_model.SGDClassifier()\n",
    "  selector = sklearn.feature_selection.RFECV(classifier, step=1)\n",
    "  selector = selector.fit(numpy.array(get_training_feature_vector()), numpy.array(get_training_labels()))\n",
    "  return {\n",
    "    'n_features': selector.n_features_,\n",
    "    'support': map(int, selector.support_),\n",
    "    'ranking': map(int, selector.ranking_),\n",
    "  }\n",
    "\n",
    "def get_selected_features_chi2():\n",
    "  selector = sklearn.feature_selection.chi2(numpy.array(get_training_feature_vector()), numpy.array(get_training_labels()))\n",
    "  return {\n",
    "    'chi2': selector[0],\n",
    "    'pval': selector[1],\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'classifier_allfeatures_randomforest.pickle'\n",
    "if path.exists(pickle_file):\n",
    "  classifier = pickle.load(open(pickle_file))\n",
    "else:\n",
    "  classifier = get_classifier()\n",
    "  pickle.dump(classifier, open(pickle_file, 'w'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_features = get_training_feature_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for line in training_features:\n",
    "#  if line[4] == 1:\n",
    "#    print line\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = extract_secondlevel_dataset_from_user(training_users[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature_vectors = dataset_to_feature_vectors(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for line in feature_vectors:\n",
    "#  if line[5] == 1:\n",
    "#    print line\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fromdomain_set = set(dataset['fromdomain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print domain_to_id(top_n_domains_by_visits()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print [x for x in fromdomain_set if id_to_domain(x) == 'www.mturk.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'get_selected_features_chi2'\n",
    "print datetime.datetime.fromtimestamp(time.time())\n",
    "print get_selected_features_chi2()\n",
    "print 'get_selected_features_rfe'\n",
    "print datetime.datetime.fromtimestamp(time.time())\n",
    "print get_selected_features_rfe()\n",
    "print 'get_selected_features_rfecv'\n",
    "print datetime.datetime.fromtimestamp(time.time())\n",
    "print get_selected_features_rfecv()\n",
    "#print get_selected_features_rfe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print selector.support_\n",
    "#print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classifier = get_classifier()\n",
    "#evaluate_classifier(classifier)\n",
    "#evaluate_classifier(get_classifier())\n",
    "#classifier = get_classifier()\n",
    "#test_predictions = make_predictions_with_classifier_on_test(classifier)\n",
    "'''\n",
    "precision_all,recall_all,_ = sklearn.metrics.precision_recall_curve(get_test_labels(), test_predictions)\n",
    "\n",
    "best_f1 = 0.0\n",
    "precision = 0.0\n",
    "recall = 0.0\n",
    "for x,y in zip(precision_all,recall_all):\n",
    "  f1 = 2*(x*y)/(x+y)\n",
    "  if f1 > best_f1:\n",
    "    best_f1 = f1\n",
    "    precision = x\n",
    "    recall = y\n",
    "print best_f1, precision, recall\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
